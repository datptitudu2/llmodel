"""
Convert HuggingFace model sang GGUF
C√°ch ƒë∆°n gi·∫£n: D√πng script Python
"""

import os
import sys
from pathlib import Path

HF_MODEL_PATH = "models/cookbot-merged"
GGUF_OUTPUT = "models/cookshare.gguf"

print("=" * 60)
print("üîÑ CONVERT HUGGINGFACE MODEL SANG GGUF")
print("=" * 60)

# Check model path
if not os.path.exists(HF_MODEL_PATH):
    print(f"‚ùå Kh√¥ng t√¨m th·∫•y: {HF_MODEL_PATH}")
    print("üëâ Gi·∫£i n√©n cookbot-merged.zip v√†o models/cookbot-merged/")
    sys.exit(1)

if not os.path.exists(f"{HF_MODEL_PATH}/model.safetensors"):
    print(f"‚ùå Kh√¥ng t√¨m th·∫•y model.safetensors trong {HF_MODEL_PATH}")
    sys.exit(1)

print(f"‚úÖ T√¨m th·∫•y model t·∫°i: {HF_MODEL_PATH}")

# Check llama.cpp
LLAMA_CPP_PATH = Path("F:/llama.cpp")
if not LLAMA_CPP_PATH.exists():
    print("\n‚ùå Kh√¥ng t√¨m th·∫•y llama.cpp t·∫°i F:/llama.cpp")
    print("\nüìù H∆∞·ªõng d·∫´n:")
    print("=" * 60)
    print("""
C√ÅCH 1: D√πng llama.cpp (Khuy·∫øn ngh·ªã)

1. Clone llama.cpp (n·∫øu ch∆∞a c√≥):
   cd F:\\
   git clone https://github.com/ggerganov/llama.cpp.git

2. C√†i transformers:
   pip install transformers

3. Convert:
   cd F:\\llama.cpp
   python convert_hf_to_gguf.py F:\\modelllmchatbot\\models\\cookbot-merged --outfile F:\\modelllmchatbot\\models\\cookshare.gguf --outtype f16

C√ÅCH 2: Upload l√™n Hugging Face v√† d√πng convert tool online

1. T·∫°o repo tr√™n Hugging Face
2. Upload model l√™n
3. D√πng convert tool online

C√ÅCH 3: D√πng Colab ƒë·ªÉ convert (ƒê∆°n gi·∫£n nh·∫•t!)

1. Upload cookbot-merged l√™n Google Drive
2. M·ªü Colab notebook
3. Ch·∫°y convert script tr√™n Colab
4. Download GGUF v·ªÅ
    """)
    print("=" * 60)
    sys.exit(1)

# Check transformers
try:
    import transformers
    print(f"‚úÖ transformers version: {transformers.__version__}")
except ImportError:
    print("\n‚ùå Ch∆∞a c√†i transformers")
    print("üëâ Ch·∫°y: pip install transformers")
    sys.exit(1)

# Convert
print(f"\nüîÑ Converting...")
print(f"   Input: {HF_MODEL_PATH}")
print(f"   Output: {GGUF_OUTPUT}")

convert_script = LLAMA_CPP_PATH / "convert_hf_to_gguf.py"
if not convert_script.exists():
    print(f"‚ùå Kh√¥ng t√¨m th·∫•y: {convert_script}")
    sys.exit(1)

# Run convert
import subprocess
cmd = [
    sys.executable,
    str(convert_script),
    os.path.abspath(HF_MODEL_PATH),
    "--outfile",
    os.path.abspath(GGUF_OUTPUT),
    "--outtype",
    "f16"
]

print(f"\nüìù Ch·∫°y l·ªánh:")
print(" ".join(cmd))
print()

try:
    result = subprocess.run(cmd, check=True, cwd=str(LLAMA_CPP_PATH))
    print("\n" + "=" * 60)
    print("‚úÖ CONVERT HO√ÄN TH√ÄNH!")
    print(f"üìÅ File: {GGUF_OUTPUT}")
    if os.path.exists(GGUF_OUTPUT):
        size_mb = os.path.getsize(GGUF_OUTPUT) / (1024 * 1024)
        print(f"üíæ Size: {size_mb:.1f} MB")
    print("=" * 60)
except subprocess.CalledProcessError as e:
    print(f"\n‚ùå L·ªói khi convert: {e}")
    print("\nüí° Th·ª≠ c√°ch kh√°c:")
    print("   1. C√†i transformers: pip install transformers")
    print("   2. Ch·∫°y l·∫°i script n√†y")
    sys.exit(1)

